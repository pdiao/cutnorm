{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools as it\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from numba import jit\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pingkoc/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/pingkoc/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import inference code\n",
    "from dbf_testing import dbf_test\n",
    "# import prediction code\n",
    "from sklearn import neighbors\n",
    "from sklearn import grid_search\n",
    "\n",
    "knn_error_metric = \"accuracy\"\n",
    "knn_p = 1\n",
    "knn_parameters = {\"weights\":('uniform', 'distance'), \"p\":(knn_p,)}    \n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "# parameters = {'n_neighbors': np.logspace(np.log10(1), np.log10(len(y_sub)/2), 10, dtype=int), \"weights\":('uniform', 'distance'), \"p\":(1, 2)}\n",
    "# grid = grid_search.GridSearchCV(knn, parameters, cv=ncv, scoring=error_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd #panda library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data function\n",
    "def load_idxlist(datadir):\n",
    "    '''\n",
    "    idxlist = list of loaded subject ids\n",
    "    '''\n",
    "    idxlist = [] # This is a list \n",
    "    \n",
    "    for fh in sorted(glob.glob(datadir+\"/*.txt\")): # look for files like sub01.txt\n",
    "        sub = int(((fh.split(\"/\")[-1]).split(\".\")[0]).lstrip('sub')) # get subject ID\n",
    "        idxlist.append(sub)\n",
    "        \n",
    "    return idxlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_distmatrix(infile):\n",
    "    X = np.loadtxt(infile, delimiter = \",\")\n",
    "    X = X + np.transpose(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pingkoc/Sanmi/cutnorm/russome/cutnorm_data/corrdist_0.1_lw.csv\n"
     ]
    }
   ],
   "source": [
    "indir = os.path.join(\"/home\", \"pingkoc\", \"Sanmi\", \"cutnorm\", \"russome\", \"cutnorm_data\")\n",
    "idx = 1\n",
    "infile = os.path.join(indir, \"%s%1d_lw.csv\"%(\"corrdist_0.\", idx,))\n",
    "print(infile)\n",
    "distmatrix = load_distmatrix(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_behav_data(behaviorfile, newidx):\n",
    "    # load the behavior files\n",
    "    behaviors = pd.io.parsers.read_csv(behaviorfile, sep='\\t', na_values=\".\")\n",
    "    # only look at behaviors whose networks we've analyzed\n",
    "    behaviors['idx'] = behaviors['Isubcode']\n",
    "    for (i,j) in enumerate(behaviors['idx']):\n",
    "        behaviors['idx'][i] = int(behaviors['idx'][i].lstrip('sub'))\n",
    "\n",
    "    val_mask = [0]*len(behaviors['idx'])\n",
    "    for (i,idx) in enumerate(behaviors['idx']):\n",
    "        val_mask[i] = (idx in newidx)\n",
    "        \n",
    "    behaviors = behaviors.loc[val_mask]\n",
    "    \n",
    "    # convert to dictionary\n",
    "    outdata = behaviors.to_dict(orient='list')\n",
    "    for key, val in outdata.items():\n",
    "        outdata[key] = np.array(val)\n",
    "    \n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.join(\"/home\", \"pingkoc\", \"Sanmi\", \"cutnorm\", \"russome\", \"data\")\n",
    "idxlist = load_idxlist(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pingkoc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "behaviorfile = \"trackingdata.txt\"\n",
    "targets = load_behav_data(behaviorfile, idxlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessor(ydict, kmax=5, nfrac=.10, amin = 5):\n",
    "    N = len(ydict)\n",
    "    for kx, vx in ydict.items():\n",
    "        K = len(vx)\n",
    "        break\n",
    "    \n",
    "    selected = dict()\n",
    "    outydict = dict()\n",
    "    outbins  = dict()\n",
    "    for idx, (ykey, yval) in enumerate(ydict.items()):\n",
    "        \n",
    "        if len(yval)<10:\n",
    "            continue\n",
    "        \n",
    "        #print ykey, yval[:10]\n",
    "        \n",
    "        # remove Nans\n",
    "        try:\n",
    "            topselect = np.logical_not(np.isnan(yval))\n",
    "        except: # probably string. Skip and let others handle it\n",
    "            topselect = np.ones(len(yval), dtype=bool)\n",
    "            #print \"continue-NaN\"\n",
    "            #continue\n",
    "            \n",
    "        ymasked = yval[topselect]\n",
    "        # check how may bins you have\n",
    "        yuniq, yinv, ycount = np.unique(ymasked, return_inverse=True, return_counts=True)\n",
    "        \n",
    "        # check if discrete or continuous\n",
    "        bins = None\n",
    "        if len(ycount) > len(ymasked)/2: # likely contunous variables\n",
    "            try:\n",
    "                ymasked = np.array(ymasked, dtype=float) # double check\n",
    "            except: # skip this. Its is not convertible, but takes too many values for discrete\n",
    "                continue \n",
    "            \n",
    "            # reset he values based on histogram\n",
    "            _, bins = np.histogram(ymasked, bins=kmax)\n",
    "            ymasked = np.digitize(ymasked, bins, right=True)\n",
    "                    \n",
    "            # re-initialize unique count using digitized results\n",
    "            yuniq, yinv, ycount = np.unique(ymasked, return_inverse=True, return_counts=True)\n",
    "        \n",
    "        \n",
    "        yselect = np.ones(shape=(len(ycount),), dtype=bool) # sub-selector using counts\n",
    "        \n",
    "        # remove elements with less than absolute min count\n",
    "        yselect[ycount<amin] = False\n",
    "        \n",
    "        # determine threshold count, and remove bins with too few\n",
    "        nmin = .25*ycount.max()\n",
    "        yselect[ycount<nmin] = False\n",
    "        \n",
    "        # select up to kmax of the remaining\n",
    "        temp = np.sort(ycount[yselect])[::-1]\n",
    "        if len(temp) > kmax:\n",
    "            yselect[ycount<temp[kmax]] = False\n",
    "            # prune\n",
    "        # else, do-nothing\n",
    "        \n",
    "        # check if more than two groups remain\n",
    "        if len(ycount[yselect]) >= 2:\n",
    "            idxselect = yselect[yinv]\n",
    "            \n",
    "            # print len(topselect), topselect.sum(), len(idxselect), idxselect.sum()\n",
    "            selected[ykey] = topselect\n",
    "            selected[ykey][topselect] = idxselect # selected index\n",
    "            \n",
    "            outydict[ykey] = yinv[idxselect] # binned version of Y\n",
    "            outbins[ykey] = bins\n",
    "        else:\n",
    "            #print \"continue-end\"\n",
    "            continue\n",
    "    \n",
    "\n",
    "    return selected, outydict, outbins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute p value for each variable\n",
    "def inferencePrediction(distance_matrix, targets, ncv=5, kmax=5, nfrac=.10, amin=5):\n",
    "    ''' computes p values and CV score for each target used as a grouping\n",
    "    '''\n",
    "    keylist = []\n",
    "    pvals = []\n",
    "    scores = []\n",
    "    baseline = []\n",
    "    \n",
    "    # distance_matrix preloaded\n",
    "    \n",
    "    # compute vallid y's\n",
    "    selected, subYdict = preprocessor(targets, kmax=kmax, nfrac=nfrac, amin=amin)[:2]\n",
    "    \n",
    "    for cnt, (ykey, idx) in enumerate(selected.items()):\n",
    "        \n",
    "        subY = subYdict[ykey]\n",
    "        #print ykey, subY\n",
    "        \n",
    "        subdistance = distance_matrix[idx][:, idx]\n",
    "        \n",
    "        # keys\n",
    "        keylist.append(ykey)\n",
    "        \n",
    "        # pvalue\n",
    "        pval = dbf_test(subdistance, subY)[0]\n",
    "        pvals.append(pval)\n",
    "        \n",
    "        # classifier\n",
    "        knn_parameters['n_neighbors'] = np.logspace(np.log10(1), np.log10(len(subY)/2), 10, dtype=int)\n",
    "        knn_parameters['metric'] = ('precomputed',)\n",
    "        grid = grid_search.GridSearchCV(knn, knn_parameters, cv=ncv, scoring=knn_error_metric)\n",
    "        grid.fit(subdistance, subY)\n",
    "        scores.append(1.0 - grid.best_score_) # see grid.grid_scores_, convert to error rate\n",
    "        \n",
    "        # compute baseline\n",
    "        baseline.append(1.0 - 1.0*np.max(np.bincount(subY))/len(subY))\n",
    "        \n",
    "        print(cnt, ykey, pvals[-1], scores[-1], baseline[-1])\n",
    "        #if cnt>10:\n",
    "            #break\n",
    "    \n",
    "    return np.array(keylist), np.array(pvals), np.array(scores), np.array(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_and_plot(distancematrix, targets, outdir):\n",
    "    #print len(inferencePrediction(X, targets))\n",
    "    keylist, pvals, scores, baseline = inferencePrediction(distancematrix, targets)\n",
    "    # save result to text\n",
    "    \n",
    "    outfile = os.path.join(outdir, \"keylist.txt\")\n",
    "    np.savetxt(outfile, keylist, fmt='%s', delimiter='\\t') \n",
    "    outfile = os.path.join(outdir, \"pvals_errors.txt\")\n",
    "    np.savetxt(outfile, np.vstack((pvals, scores)).T, fmt=['%g', '%g'], delimiter='\\t')\n",
    "    \n",
    "    # sort by average values\n",
    "    sortidx = (scale(pvals)+scale(scores)).argsort()[::-1]\n",
    "    bestkeys = keylist[sortidx]\n",
    "    bestp = pvals[sortidx]\n",
    "    bests = scores[sortidx]\n",
    "    baseline = baseline[sortidx]\n",
    "                                                           \n",
    "    outfile = os.path.join(outdir, \"bestkeylist.txt\")\n",
    "    np.savetxt(outfile, bestkeys, fmt='%s', delimiter='\\t')\n",
    "    outfile = os.path.join(outdir, \"bestlist.txt\")\n",
    "    np.savetxt(outfile, np.vstack((bestp, bests, baseline)).T, fmt=['%g', '%g', '%g'], delimiter='\\t')\n",
    "    \n",
    "    # save figure\n",
    "    comb = {\"pvalues\": pd.Series(pvals, index=keylist),\n",
    "            \"error_rate\":pd.Series(scores, index=keylist)}\n",
    "    combined = pd.DataFrame(comb)\n",
    "    \n",
    "    outfile = os.path.join(outdir, \"pvals_errors.pdf\")\n",
    "    sns.jointplot(x=\"pvalues\", y=\"error_rate\", data=combined, \n",
    "                  kind=\"reg\", xlim=(0.0, 1.0), ylim=(0.0, 1.0))\n",
    "    plt.savefig(outfile)\n",
    "    \n",
    "    return keylist, pvals, scores, baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(\"/home\", \"pingkoc\", \"Sanmi\", \"cutnorm\", \"russome\", \"results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 afterscan:Anxietyduringscan 0.69424539003 0.4117647058823529 0.455882352941\n",
      "1 afterscan:diastolic 0.840308251476 0.8421052631578947 0.815789473684\n",
      "2 afterscan:pulse 0.248391334206 0.7272727272727273 0.787878787879\n",
      "3 afterscan:systolic 0.45226374835 0.6666666666666667 0.714285714286\n",
      "4 blood:eo 0.650596098568 0.33333333333333337 0.416666666667\n",
      "5 blood:hgb 0.0913591956923 0.4 0.5\n",
      "6 blood:ly 0.557101163862 0.41666666666666663 0.416666666667\n",
      "7 blood:ne 0.88776202076 0.5833333333333333 0.5\n",
      "8 blood:rbc 0.634943324457 0.2727272727272727 0.454545454545\n",
      "9 day_of_week 0.00299838451942 0.40963855421686746 0.518072289157\n",
      "10 email:LIWC_CDI 0.254120545258 0.5068493150684932 0.602739726027\n",
      "11 email:LIWC_negemo 0.740713434946 0.3731343283582089 0.388059701493\n",
      "12 email:LIWC_posemo 0.204418899813 0.45833333333333337 0.583333333333\n",
      "13 morning:Pulse 0.175745996483 0.7948717948717949 0.769230769231\n",
      "14 morning:Sleepquality 0.26490467743 0.5526315789473684 0.592105263158\n",
      "15 morning:Soreness 0.293945403203 0.524390243902439 0.609756097561\n",
      "16 morning:diastolic 0.946708940969 0.75 0.772727272727\n",
      "17 morning:systolic 0.151186117612 0.7435897435897436 0.846153846154\n",
      "18 panas:active 0.357339480333 0.25 0.266666666667\n",
      "19 panas:alert 0.0485059580465 0.22058823529411764 0.220588235294\n",
      "20 panas:astonished 0.777950582214 0.21739130434782605 0.231884057971\n",
      "21 panas:bold 0.0492347844255 0.36923076923076925 0.4\n",
      "22 panas:cheerful 0.470099977785 0.37681159420289856 0.391304347826\n",
      "23 panas:concentrating 0.0019488480891 0.31343283582089554 0.328358208955\n",
      "24 panas:confident 0.148216420442 0.303030303030303 0.409090909091\n",
      "25 panas:daring 0.297049691322 0.29508196721311475 0.295081967213\n",
      "26 panas:delighted 0.38043310763 0.6081081081081081 0.635135135135\n",
      "27 panas:determined 0.184373780772 0.34782608695652173 0.36231884058\n",
      "28 panas:distressed 0.179036820119 0.2571428571428571 0.257142857143\n",
      "29 panas:drowsy 0.061971444471 0.3870967741935484 0.403225806452\n",
      "30 panas:energetic 0.345094469268 0.43661971830985913 0.43661971831\n",
      "31 panas:enthusiastic 0.463867777257 0.24615384615384617 0.338461538462\n",
      "32 panas:excited 0.123140811905 0.5810810810810811 0.581081081081\n",
      "33 panas:fatigue 0.226297007162 0.42000000000000004 0.5\n",
      "34 panas:fearless 0.0973767989432 0.25396825396825395 0.253968253968\n",
      "35 panas:happy 0.462354165102 0.3939393939393939 0.393939393939\n",
      "36 panas:inspired 0.151686639188 0.4328358208955224 0.462686567164\n",
      "37 panas:interested 0.668063741039 0.3939393939393939 0.393939393939\n",
      "38 panas:joyful 0.919005005969 0.47887323943661975 0.478873239437\n",
      "39 panas:lively 0.00880047580217 0.5 0.542857142857\n",
      "40 panas:positive 0.374943282915 0.6666666666666667 0.75\n",
      "41 panas:proud 1.0 0.4307692307692308 0.476923076923\n",
      "42 panas:relaxed 0.242714405572 0.2063492063492064 0.253968253968\n",
      "43 panas:sleepy 0.266676574124 0.3709677419354839 0.403225806452\n",
      "44 panas:sluggish 0.0719764753956 0.29508196721311475 0.409836065574\n",
      "45 panas:strong 0.637255865628 0.38235294117647056 0.382352941176\n",
      "46 panas:surprised 1.0 0.24615384615384617 0.246153846154\n",
      "47 panas:tired 0.295695187219 0.2931034482758621 0.362068965517\n",
      "48 panas:upset 0.75438211913 0.2571428571428571 0.257142857143\n",
      "49 prevevening:Alcohol 0.0276169238132 0.5 0.616666666667\n",
      "50 prevevening:Guthealth 0.35158610007 0.515625 0.609375\n",
      "51 prevevening:Howmuchdidtinnitusbotheryoutoday? 0.915972057246 0.42105263157894735 0.473684210526\n",
      "52 prevevening:Psoriasisseverity 0.520154276355 0.5692307692307692 0.553846153846\n",
      "53 prevevening:Stress 0.282180934863 0.5072463768115942 0.507246376812\n",
      "54 prevevening:Timespentoutdoors 0.0130854955575 0.43137254901960786 0.470588235294\n",
      "55 rna:rin 0.100961506664 0.2647058823529411 0.294117647059\n",
      "56 sameevening:Guthealth 1.0 0.5593220338983051 0.610169491525\n",
      "57 sameevening:Howmuchdidtinnitusbotheryoutoday? 0.881989831979 0.7 0.5\n",
      "58 sameevening:Psoriasisseverity 0.907541425665 0.6166666666666667 0.6\n",
      "59 sameevening:Stress 0.0351474180957 0.26315789473684215 0.333333333333\n",
      "60 sameevening:Timespentoutdoors 0.502002512912 0.4782608695652174 0.478260869565\n",
      "61 scan:has_breathhold 0.0529632163138 0.2142857142857143 0.214285714286\n",
      "62 weather:temphi 0.00100479689808 0.5061728395061729 0.62962962963\n",
      "63 weather:templo 0.848009382285 0.4 0.5\n",
      "64 weight 0.0876694811878 0.625 0.6\n",
      "65 zeo:timeInDeep 0.194691853034 0.5106382978723405 0.63829787234\n",
      "66 zeo:timeInLight 0.334124182887 0.5714285714285714 0.571428571429\n",
      "67 zeo:timeInRem 0.731941402522 0.43181818181818177 0.454545454545\n",
      "68 zeo:totalZ 0.040293656298 0.22499999999999998 0.225\n",
      "69 zeo:zq 0.0955561046202 0.45238095238095233 0.452380952381\n",
      "70 idx 0.00188404862292 0.6024096385542168 0.78313253012\n"
     ]
    }
   ],
   "source": [
    "keylist, pvals, scores, baseline = compute_and_plot(distmatrix, targets, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected, subYdict = preprocessor(targets)[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "testy = selected['panas:strong']\n",
    "testy1 = distmatrix[testy][:,testy]\n",
    "print(len(testy1[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subY = subYdict['panas:strong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=22, metric = 'precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66176470588235292"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(testy1,subY)\n",
    "knn.score(testy1,subY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38235294117647056"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(subY == 1)*1.0/len(subY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_parameters['n_neighbors'] = np.logspace(np.log10(1), np.log10(len(subY)/2), 10, dtype=int)\n",
    "knn_parameters['metric'] = ('precomputed',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': ('precomputed',),\n",
       " 'n_neighbors': array([ 1,  1,  2,  3,  4,  7, 10, 15, 22, 34]),\n",
       " 'p': (1,),\n",
       " 'weights': ('uniform', 'distance')}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38235294117647056\n"
     ]
    }
   ],
   "source": [
    "grid = grid_search.GridSearchCV(knn, knn_parameters, cv=5, scoring=knn_error_metric)\n",
    "grid.fit(testy1, subY)\n",
    "print(1.0 - grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
