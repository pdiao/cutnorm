{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools as it\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from numba import jit\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Anaconda3\\envs\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Peter\\Anaconda3\\envs\\python27\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import inference code\n",
    "from dbf_testing import dbf_test\n",
    "# import prediction code\n",
    "from sklearn import neighbors\n",
    "from sklearn import grid_search\n",
    "\n",
    "knn_error_metric = \"accuracy\"\n",
    "knn_p = 1\n",
    "knn_parameters = {\"weights\":('uniform', 'distance'), \"p\":(knn_p,)}    \n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "# parameters = {'n_neighbors': np.logspace(np.log10(1), np.log10(len(y_sub)/2), 10, dtype=int), \"weights\":('uniform', 'distance'), \"p\":(1, 2)}\n",
    "# grid = grid_search.GridSearchCV(knn, parameters, cv=ncv, scoring=error_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd #panda library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading data function\n",
    "def load_idxlist(datadir):\n",
    "    '''\n",
    "    idxlist = list of loaded subject ids\n",
    "    '''\n",
    "    idxlist = [] # This is a list \n",
    "    \n",
    "    for fh in sorted(glob.glob(datadir+\"\\\\*.txt\")): # look for files like sub01.txt\n",
    "        sub = int(((fh.split(\"\\\\\")[-1]).split(\".\")[0]).lstrip('sub')) # get subject ID\n",
    "        idxlist.append(sub)\n",
    "        \n",
    "    return idxlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_distmatrix(infile):\n",
    "    X = np.loadtxt(infile, delimiter = \",\")\n",
    "    X = X + np.transpose(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Dropbox\\Documents(newlaptop)\\Neuroscience\\cutnorm\\FOptM\\FOptM-share\\corrdist_0.10_lw.csv\n"
     ]
    }
   ],
   "source": [
    "indir = os.path.join(\"C:\\Users\", \"Peter\", \"Dropbox\", \"Documents(newlaptop)\", \"Neuroscience\", \"cutnorm\", \"FOptM\", \"FOptM-share\")\n",
    "idx = 10\n",
    "infile = os.path.join(indir, \"%s%02d_lw.csv\"%(\"corrdist_0.\", idx,))\n",
    "print infile\n",
    "distmatrix = load_distmatrix(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_behav_data(behaviorfile, newidx):\n",
    "    # load the behavior files\n",
    "    behaviors = pd.io.parsers.read_csv(behaviorfile, sep='\\t', na_values=\".\")\n",
    "    # only look at behaviors whose networks we've analyzed\n",
    "    behaviors['idx'] = behaviors['Isubcode']\n",
    "    for (i,j) in enumerate(behaviors['idx']):\n",
    "        behaviors['idx'][i] = int(behaviors['idx'][i].lstrip('sub'))\n",
    "\n",
    "    val_mask = [0]*len(behaviors['idx'])\n",
    "    for (i,idx) in enumerate(behaviors['idx']):\n",
    "        val_mask[i] = (idx in newidx)\n",
    "        \n",
    "    behaviors = behaviors.loc[val_mask]\n",
    "    \n",
    "    # convert to dictionary\n",
    "    outdata = behaviors.to_dict(orient='list')\n",
    "    for key, val in outdata.iteritems():\n",
    "        outdata[key] = np.array(val)\n",
    "    \n",
    "    return outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = os.path.join(\"C:\\Users\", \"Peter\", \"Dropbox\", \"Documents(newlaptop)\", \"Neuroscience\", \"cutnorm\", \"FOptM\", \"FOptM-share\", \"data\", \"updated\")\n",
    "idxlist = load_idxlist(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\Anaconda3\\envs\\python27\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "behaviorfile = \"trackingdata.txt\"\n",
    "targets = load_behav_data(behaviorfile, idxlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessor(ydict, kmax=5, nfrac=.10, amin = 5):\n",
    "    N = len(ydict)\n",
    "    for kx, vx in ydict.iteritems():\n",
    "        K = len(vx)\n",
    "        break\n",
    "    \n",
    "    selected = dict()\n",
    "    outydict = dict()\n",
    "    outbins  = dict()\n",
    "    for idx, (ykey, yval) in enumerate(ydict.iteritems()):\n",
    "        \n",
    "        if len(yval)<10:\n",
    "            continue\n",
    "        \n",
    "        #print ykey, yval[:10]\n",
    "        \n",
    "        # remove Nans\n",
    "        try:\n",
    "            topselect = np.logical_not(np.isnan(yval))\n",
    "        except: # probably string. Skip and let others handle it\n",
    "            topselect = np.ones(len(yval), dtype=bool)\n",
    "            #print \"continue-NaN\"\n",
    "            #continue\n",
    "            \n",
    "        ymasked = yval[topselect]\n",
    "        # check how may bins you have\n",
    "        yuniq, yinv, ycount = np.unique(ymasked, return_inverse=True, return_counts=True)\n",
    "        \n",
    "        # check if discrete or continuous\n",
    "        bins = None\n",
    "        if len(ycount) > len(ymasked)/2: # likely contunous variables\n",
    "            try:\n",
    "                ymasked = np.array(ymasked, dtype=float) # double check\n",
    "            except: # skip this. Its is not convertible, but takes too many values for discrete\n",
    "                continue \n",
    "            \n",
    "            # reset he values based on histogram\n",
    "            _, bins = np.histogram(ymasked, bins=kmax)\n",
    "            ymasked = np.digitize(ymasked, bins, right=True)\n",
    "                    \n",
    "            # re-initialize unique count using digitized results\n",
    "            yuniq, yinv, ycount = np.unique(ymasked, return_inverse=True, return_counts=True)\n",
    "        \n",
    "        \n",
    "        yselect = np.ones(shape=(len(ycount),), dtype=bool) # sub-selector using counts\n",
    "        \n",
    "        # remove elements with less than absolute min count\n",
    "        yselect[ycount<amin] = False\n",
    "        \n",
    "        # determine threshold count, and remove bins with too few\n",
    "        nmin = .25*ycount.max()\n",
    "        yselect[ycount<nmin] = False\n",
    "        \n",
    "        # select up to kmax of the remaining\n",
    "        temp = np.sort(ycount[yselect])[::-1]\n",
    "        if len(temp) > kmax:\n",
    "            yselect[ycount<temp[kmax]] = False\n",
    "            # prune\n",
    "        # else, do-nothing\n",
    "        \n",
    "        # check if more than two groups remain\n",
    "        if len(ycount[yselect]) >= 2:\n",
    "            idxselect = yselect[yinv]\n",
    "            \n",
    "            # print len(topselect), topselect.sum(), len(idxselect), idxselect.sum()\n",
    "            selected[ykey] = topselect\n",
    "            selected[ykey][topselect] = idxselect # selected index\n",
    "            \n",
    "            outydict[ykey] = yinv[idxselect] # binned version of Y\n",
    "            outbins[ykey] = bins\n",
    "        else:\n",
    "            #print \"continue-end\"\n",
    "            continue\n",
    "                    \n",
    "    return selected, outydict, outbins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute p value for each variable\n",
    "def inferencePrediction(distance_matrix, targets, ncv=5, kmax=5, nfrac=.10, amin=5):\n",
    "    ''' computes p values and CV score for each target used as a grouping\n",
    "    '''\n",
    "    keylist = []\n",
    "    pvals = []\n",
    "    scores = []\n",
    "    baseline = []\n",
    "    \n",
    "    # distance_matrix preloaded\n",
    "    \n",
    "    # compute vallid y's\n",
    "    selected, subYdict = preprocessor(targets, kmax=kmax, nfrac=nfrac, amin=amin)[:2]\n",
    "    \n",
    "    for cnt, (ykey, idx) in enumerate(selected.iteritems()):\n",
    "        \n",
    "        subY = subYdict[ykey]\n",
    "        #print ykey, subY\n",
    "        \n",
    "        subdistance = distance_matrix[idx][:, idx]\n",
    "        \n",
    "        # keys\n",
    "        keylist.append(ykey)\n",
    "        \n",
    "        # pvalue\n",
    "        pval = dbf_test(subdistance, subY)[0]\n",
    "        pvals.append(pval)\n",
    "        \n",
    "        # classifier\n",
    "        knn_parameters['n_neighbors'] = np.logspace(np.log10(1), np.log10(len(subY)/2), 10, dtype=int)\n",
    "        knn_parameters['metric'] = ('precomputed',)\n",
    "        grid = grid_search.GridSearchCV(knn, knn_parameters, cv=ncv, scoring=knn_error_metric)\n",
    "        grid.fit(subdistance, subY)\n",
    "        scores.append(1.0 - grid.best_score_) # see grid.grid_scores_, convert to error rate\n",
    "        \n",
    "        # compute baseline\n",
    "        baseline.append(1.0 - 1.0*np.max(np.bincount(subY))/len(subY))\n",
    "        \n",
    "        print cnt, ykey, pvals[-1], scores[-1], baseline[-1]\n",
    "        #if cnt>10:\n",
    "            #break\n",
    "    \n",
    "    return np.array(keylist), np.array(pvals), np.array(scores), np.array(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_and_plot(distancematrix, targets, outdir):\n",
    "    #print len(inferencePrediction(X, targets))\n",
    "    keylist, pvals, scores, baseline = inferencePrediction(distancematrix, targets)\n",
    "    # save result to text\n",
    "    \n",
    "    outfile = os.path.join(outdir, \"keylist.txt\")\n",
    "    np.savetxt(outfile, keylist, fmt='%s', delimiter='\\t') \n",
    "    outfile = os.path.join(outdir, \"pvals_errors.txt\")\n",
    "    np.savetxt(outfile, np.vstack((pvals, scores)).T, fmt=['%g', '%g'], delimiter='\\t')\n",
    "    \n",
    "    # sort by average values\n",
    "    sortidx = (scale(pvals)+scale(scores)).argsort()[::-1]\n",
    "    bestkeys = keylist[sortidx]\n",
    "    bestp = pvals[sortidx]\n",
    "    bests = scores[sortidx]\n",
    "    baseline = baseline[sortidx]\n",
    "                                                           \n",
    "    outfile = os.path.join(outdir, \"bestkeylist.txt\")\n",
    "    np.savetxt(outfile, bestkeys, fmt='%s', delimiter='\\t')\n",
    "    outfile = os.path.join(outdir, \"bestlist.txt\")\n",
    "    np.savetxt(outfile, np.vstack((bestp, bests, baseline)).T, fmt=['%g', '%g', '%g'], delimiter='\\t')\n",
    "    \n",
    "    # save figure\n",
    "    comb = {\"pvalues\": pd.Series(pvals, index=keylist),\n",
    "            \"error_rate\":pd.Series(scores, index=keylist)}\n",
    "    combined = pd.DataFrame(comb)\n",
    "    \n",
    "    outfile = os.path.join(outdir, \"pvals_errors.pdf\")\n",
    "    sns.jointplot(x=\"pvalues\", y=\"error_rate\", data=combined, \n",
    "                  kind=\"reg\", xlim=(0.0, 1.0), ylim=(0.0, 1.0))\n",
    "    plt.savefig(outfile)\n",
    "    \n",
    "    return keylist, pvals, scores, baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = os.path.join(\"C:\\Users\",\"Peter\", \"Desktop\", \"JSM2017\", \"Neuroscience\",\"cutnorm\",\"FOptM\",\"FOptM-share\", \"results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 sameevening:Howmuchdidtinnitusbotheryoutoday? 0.881901120424 0.7 0.5\n",
      "1 panas:enthusiastic 0.46372490911 0.246153846154 0.338461538462\n",
      "2 weight 0.0877830743869 0.625 0.6\n",
      "3 sameevening:Timespentoutdoors 0.502718254943 0.478260869565 0.478260869565\n",
      "4 panas:upset 0.754538890943 0.257142857143 0.257142857143\n",
      "5 panas:proud 1.0 0.430769230769 0.476923076923\n",
      "6 sameevening:Guthealth 1.0 0.559322033898 0.610169491525\n",
      "7 panas:distressed 0.178942755336 0.257142857143 0.257142857143\n",
      "8 panas:alert 0.0484771820113 0.220588235294 0.220588235294\n",
      "9 sameevening:Stress 0.0352308568635 0.263157894737 0.333333333333\n",
      "10 prevevening:Guthealth 0.352144579993 0.515625 0.609375\n",
      "11 afterscan:Anxietyduringscan 0.694914783196 0.411764705882 0.455882352941\n",
      "12 blood:eo 0.649768141812 0.333333333333 0.416666666667\n",
      "13 afterscan:systolic 0.451435978111 0.666666666667 0.714285714286\n",
      "14 panas:determined 0.184372691974 0.347826086957 0.36231884058\n",
      "15 afterscan:diastolic 0.840330657559 0.842105263158 0.815789473684\n",
      "16 email:LIWC_negemo 0.740745417065 0.373134328358 0.388059701493\n",
      "17 panas:strong 0.63792696683 0.382352941176 0.382352941176\n",
      "18 prevevening:Psoriasisseverity 0.520164174925 0.569230769231 0.553846153846\n",
      "19 zeo:timeInDeep 0.194819892 0.510638297872 0.63829787234\n",
      "20 panas:energetic 0.346228777109 0.43661971831 0.43661971831\n",
      "21 panas:inspired 0.151466160847 0.432835820896 0.462686567164\n",
      "22 panas:positive 0.375384660392 0.666666666667 0.75\n",
      "23 panas:relaxed 0.242457930656 0.206349206349 0.253968253968\n",
      "24 panas:bold 0.0491988104713 0.369230769231 0.4\n",
      "25 panas:delighted 0.380819602102 0.608108108108 0.635135135135\n",
      "26 prevevening:Howmuchdidtinnitusbotheryoutoday? 0.915469598906 0.421052631579 0.473684210526\n",
      "27 panas:drowsy 0.0619544272469 0.387096774194 0.403225806452\n",
      "28 panas:daring 0.297068203472 0.295081967213 0.295081967213\n",
      "29 weather:temphi 0.00100440540449 0.493827160494 0.62962962963\n",
      "30 prevevening:Timespentoutdoors 0.0130661292544 0.43137254902 0.470588235294\n",
      "31 zeo:totalZ 0.0402925795095 0.225 0.225\n",
      "32 panas:cheerful 0.470055371444 0.376811594203 0.391304347826\n",
      "33 panas:fatigue 0.226351643366 0.42 0.5\n",
      "34 panas:fearless 0.0971303218486 0.253968253968 0.253968253968\n",
      "35 zeo:timeInRem 0.73055275807 0.431818181818 0.454545454545\n",
      "36 panas:excited 0.123259640938 0.581081081081 0.581081081081\n",
      "37 sameevening:Psoriasisseverity 0.908558321399 0.616666666667 0.6\n",
      "38 morning:systolic 0.151283434402 0.74358974359 0.846153846154\n",
      "39 panas:sluggish 0.072050361768 0.311475409836 0.409836065574\n",
      "40 morning:Pulse 0.175410901357 0.794871794872 0.769230769231\n",
      "41 morning:diastolic 0.946338294855 0.75 0.772727272727\n",
      "42 email:LIWC_posemo 0.204188753618 0.458333333333 0.583333333333\n",
      "43 prevevening:Alcohol 0.0276308483334 0.5 0.616666666667\n",
      "44 blood:rbc 0.632338513166 0.272727272727 0.454545454545\n",
      "45 scan:has_breathhold 0.0530080186435 0.214285714286 0.214285714286\n",
      "46 panas:active 0.357931576824 0.25 0.266666666667\n",
      "47 morning:Sleepquality 0.264960811084 0.552631578947 0.592105263158\n",
      "48 morning:Soreness 0.294408453147 0.524390243902 0.609756097561\n",
      "49 panas:joyful 0.918641912763 0.478873239437 0.478873239437\n",
      "50 blood:hgb 0.0916729136258 0.4 0.5\n",
      "51 zeo:timeInLight 0.334040870806 0.551020408163 0.571428571429\n",
      "52 idx 0.00188507584537 0.614457831325 0.78313253012\n",
      "53 rna:rin 0.10096159083 0.294117647059 0.294117647059\n",
      "54 prevevening:Stress 0.282057267319 0.507246376812 0.507246376812\n",
      "55 panas:lively 0.00880379051061 0.5 0.542857142857\n",
      "56 blood:ly 0.556005007854 0.416666666667 0.416666666667\n",
      "57 panas:concentrating 0.00194924549176 0.313432835821 0.328358208955\n",
      "58 day_of_week 0.0030071152281 0.409638554217 0.518072289157\n",
      "59 panas:astonished 0.777576264369 0.217391304348 0.231884057971\n",
      "60 email:LIWC_CDI 0.254300415696 0.506849315068 0.602739726027\n",
      "61 weather:templo 0.847555437217 0.4 0.5\n",
      "62 panas:tired 0.295711890521 0.293103448276 0.362068965517\n",
      "63 panas:surprised 1.0 0.246153846154 0.246153846154\n",
      "64 panas:interested 0.66735134346 0.393939393939 0.393939393939\n",
      "65 afterscan:pulse 0.247727298363 0.727272727273 0.787878787879\n",
      "66 panas:confident 0.148298484544 0.30303030303 0.409090909091\n",
      "67 zeo:zq 0.0954860331752 0.452380952381 0.452380952381\n",
      "68 panas:happy 0.462047296613 0.393939393939 0.393939393939\n",
      "69 panas:sleepy 0.266147263146 0.370967741935 0.403225806452\n",
      "70 blood:ne 0.887812006695 0.583333333333 0.5\n"
     ]
    }
   ],
   "source": [
    "keylist, pvals, scores, baseline = compute_and_plot(distmatrix, targets, outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected, subYdict = preprocessor(targets)[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "testy = selected['panas:strong']\n",
    "testy1 = distmatrix[testy][:,testy]\n",
    "print len(testy1[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subY = subYdict['panas:strong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=22, metric = 'precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55882352941176472"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(testy1,subY)\n",
    "knn.score(testy1,subY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38235294117647056"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(subY == 1)*1.0/len(subY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_parameters['n_neighbors'] = np.logspace(np.log10(1), np.log10(len(subY)/2), 10, dtype=int)\n",
    "knn_parameters['metric'] = ('precomputed',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': ('precomputed',),\n",
       " 'n_neighbors': array([ 1,  1,  2,  3,  4,  7, 10, 15, 22, 34]),\n",
       " 'p': (1,),\n",
       " 'weights': ('uniform', 'distance')}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.382352941176\n"
     ]
    }
   ],
   "source": [
    "grid = grid_search.GridSearchCV(knn, knn_parameters, cv=5, scoring=knn_error_metric)\n",
    "grid.fit(testy1, subY)\n",
    "print(1.0 - grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
